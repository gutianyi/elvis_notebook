[TOC]

## 机器学习算法

### 线性回归

### LR

### SVM

##### 损失函数：

$$
z = y_{i}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+\boldsymbol{b}\right)
$$

> 加入损失函数 实现了软间隔

0 1 损失: 

hinge损失：$$\ell_{\text {hinge}}(z)=\max (0,1-z)$$

指数损失(exponential loss): $$\ell_{e x p}(z)=\exp (-z)$$

对案损失(logistic loss): $$\ell_{\log }(z)=\log (1+\exp (-z))$$

### XGBOOST

### 随机森林

## 深度学习算法

### Tensorboard

把优化过程可视化

### DNN

### CNN

### LSTM

## 优化方法

### L1L2

### Dropout