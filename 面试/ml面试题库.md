[TOC]



### ML

##### 逻辑回归的原理

线性回归是去求出一条拟合特征空间中所有点的线，逻辑回归本质是相同的 但是加了一个sigmoid的外壳  用sigmoid来转换线性回归的输出来返回概率值， 然后根据概率值映射到两个离散类。

##### 为何逻辑回归用sigmoid

逻辑回归对应logit function，也就是说逻辑回归就是sigmoid的应用（一个对象的两个描述而已）

为什么会有这个定义呢？ 

> lr是基于伯努利分布为假设的，伯努利分布的指数族分布形式就是sigmoid函数，而且sigmoid函数可以将数据压缩到0-1内，以便表示概率

> 1. sigmoid 函数连续，单调递增
> 2. p′=p∗(1−p)计算sigmoid函数的导数非常的快速

##### 为何逻辑回归用交叉熵函数

> mse的导数里面有sigmoid函数的导数，而交叉熵导数里面没有sigmoid函数的导数，sigmoid的导数的最大值为0.25，更新数据时太慢了

##### 为啥离散特征用one-hot

##### 类别不平衡

##### xgboost和gbdt的区别

首先呢，xgboost是gbdt的一种高效系统实现。

- 传统GBDT以CART作为基分类器，xgboost还支持线性分类器，

  > （这个时候xgboost相当于带L1和L2正则化项的逻辑回归（分类问题）或者线性回归（回归问题）。）

- GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，

  > （同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。）

- xgboost在代价函数里加入了正则项，

  >  (用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和  从而来防止过拟合)

- 对缺失值的处理。

- xgboost工具支持并行。data事先排好序并以block的形式存储，利于并行计算

  > xgboost工具支持并行。boosting不是一种串行的结构吗?怎么并行的？注意xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。

- 列抽样
- 支持分布式

##### 怎么判断过拟合，你一般怎么解决

模型在验证集合上和训练集合上表现都很好，而在测试集合上变现很差。

解决：

- 增加正则项
- 获取更多的训练数据
- 降低模型复杂度（减少网络层数
- 用集成学习的方法 stacking
- 对于NN做 dropout|  BN | early stop
- 标签平滑
- 数据增强





2.lr和xgboost有什么区别 

 3.什么情况下用lr比较好 

 4.lr和svm的区别 

 5.bagging和boosting算法介绍一下 

 6.如何解决过拟合和欠拟合的问题 

 7.数据增强有什么方法 

 8.xgboost是如何训练的 

 9.kmeans的具体步骤 

 10.如何评价聚类结果的好坏。轮廓系数有没有用过。 

 11.roc曲线介绍一下。

##### 参数初始化的作用是啥

如果全部初始化为0，在神经网络第一遍前向传播所有隐层神经网络激活值相同，反向传播权重更新也相同，导致隐层神经元没有区分性，称为“对称权重”现象。为打破这个平衡，比较好的方式是对每个参数进行随机初始化。

> 每一层参数更新后的值都是相同的。后面不断的正向和反向传播，每一层的参数更新之后的值都是相同的。那么带来的问题就是：**所有参数值一样，意味着不同的结点根本无法学习到不同的特征，通过不同结点的输出值始终是相同的。这就失去了神经网络特征学习的意义。换句话说，每层所有结点的值都一样，就相当于该层只有一个结点发挥了作用。因此初始化全为0很有可能导致模型失败，无法收敛。这种现象称为“对称权重现象”。**

##### 偏差和方差

偏差(bias): 预测值与真实值之间的距离  偏差越大，越偏离真实数据

方差(variance)：描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。 方差越大，数据的分布越分散

##### 什么模型能减小方差

Bagging   可以假设不同的训练集为x_1 x_2  两者完全独立：
$$
\begin{aligned}
\operatorname{Var}\left(\frac{\sum X_{i}}{n}\right) &=\operatorname{Var}\left(\frac{X_{1}+X_{2}}{2}\right)=\frac{1}{4} \operatorname{Var}\left(X_{1}+X_{2}\right)=\frac{1}{4}\left(\operatorname{Var}\left(X_{1}\right)+\operatorname{Var}\left(X_{2}\right)\right)=\\
\frac{1}{4}\left(2 \operatorname{Var}\left(X_{1}\right)\right)=& \frac{\operatorname{Var}\left(X_{i}\right)}{2}=\frac{\operatorname{Var}\left(X_{i}\right)}{n}
\end{aligned}
$$

##### xgboost的二阶泰勒展开为啥效果那么好？

Xgboost使用二阶展开效果更好的原因，应该与牛顿法使用海塞矩阵比SGD好的原因一样 

> 二阶信息本身就能让梯度收敛更快更准确 ;可以简单认为一阶导指引梯度方向，二阶导指引梯度方向如何变化。这是从二阶导本身的性质，也就是**为什么要用泰勒二阶展开**的角度来说的

##### B+🌲

##### 降维算法  PCA怎么做的

##### 逻辑回归和线性回归的区别

##### 激活函数优缺点

##### 优化器的优缺点（SGD MOM* RMSPROPS ADAM）

##### 为何逻辑回归用sigmoid，为何逻辑回归用交叉熵函数，为啥离散特征用one-hot

##### L1 L2正则

> 从统计概率上讲，L1是laplace分布，L2是高斯分布，L1的分布对极端值能更加容忍也就是说L2比L1对outlier 大数更加敏感，对于L1更可以防止过拟合

L2 相比于 L1 对于异常值更敏感 对于L1更可以防止过拟合(因为平方的原因, L2 对于大数的乘法比对小数的惩罚大)

从求导上看 L2是连续的  计算方便 有唯一解, 约靠近0的时候 梯度就小 越无法接近0；L1不是连续的 但是梯度是固定1或者-1  L1 正则的话基本上经过一定步数后很可能变为0

L2使得权重平滑 ；L1使得权重稀疏，会把不重要的特征直接置零（从而起到特征筛选的作用）

L2 是优化常用方法



### NN

#### NLP

##### word2vec和fasttext的区别

#### LSTM

##### 1.LSTM在训练时，每个时刻的weight是否是同时变化？

##### 2.LSTM在训练时，每个时刻的weight是否会相互影响？

##### 3.简述RNN，LSTM，GRU的区别和联系

RNN：

<img src="https://raw.githubusercontent.com/gutianyi/image/master/img/rnn.jpg" style="zoom: 15%;" />

> 把RNN扩展成一个三层全神经网络(input hidden output)，每输入一步都是共享参数U V W

LSTM：



##### 4.画出lstm的结构图，写出公式

##### 5.RNN的梯度消失问题？如何解决？

##### 6.lstm中是否可以用relu作为激活函数？

##### 7.lstm各个门分别使用什么激活函数？

##### 8.LSTM 能解决 RNN 什么问题，并通过数学公式推导

##### 9.双向 LSTM 比 LSTM 好在哪

##### 10.介绍一下 LSTM 的各个门

##### 11.Transformer与LSTM区别

##### 12.Transformer相对RNN为什么能避免梯度消失



##### 梯度爆炸

对激活函数进行求导，如果导数大于1，那么随着网络层数的增加，也就是说参数是一个连乘的结果   梯度更新将会朝着指数爆炸的方式增加。同样如果导数小于1，那么随着网络层数的增加梯度更新信息会朝着指数衰减的方式减少这就是梯度消失。

##### BN 

BN的假设是如果每一层每单个神经元输入分布是归一化的，那么这将有利于优化

BN的作用是去平滑优化空间 使得梯度变得平滑稳定  正则化的作用是副产物

##### Dropout

### spark

